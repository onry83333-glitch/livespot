"""LLM Engine - Ported from sync/llm_engine.py + sync/llm_chat_analysis.py"""
import os
import anthropic
from config import get_settings


def _get_client() -> anthropic.Anthropic:
    settings = get_settings()
    return anthropic.Anthropic(api_key=settings.anthropic_api_key)


async def generate_live_assist(
    cast_name: str,
    recent_messages: list[dict],
    context: str | None = None,
) -> dict:
    """é…ä¿¡ä¸­AIã‚¢ã‚·ã‚¹ãƒˆ â€” 3ã‚»ã‚¯ã‚·ãƒ§ãƒ³å‡ºåŠ›
    ãƒ»ä»Šã™ãã‚„ã‚‹ã“ã¨
    ãƒ»é›°å›²æ°—ã®åˆ†æ
    ãƒ»æ¬¡ã®ã‚¢ã‚¯ã‚·ãƒ§ãƒ³ææ¡ˆ
    """
    client = _get_client()

    # Format messages for prompt
    msg_lines = []
    for m in recent_messages[-50:]:  # Last 50 messages
        prefix = ""
        if m.get("tokens", 0) > 0:
            prefix = f"[ğŸ{m['tokens']}tk] "
        msg_lines.append(f"{m.get('user_name', '?')}: {prefix}{m.get('message', '')}")

    messages_text = "\n".join(msg_lines)

    prompt = f"""ã‚ãªãŸã¯ãƒ©ã‚¤ãƒ–é…ä¿¡ã®æˆ¦ç•¥ã‚¢ãƒ‰ãƒã‚¤ã‚¶ãƒ¼ã§ã™ã€‚
ä»¥ä¸‹ã®ãƒãƒ£ãƒƒãƒˆãƒ­ã‚°ã‚’åˆ†æã—ã€ã‚­ãƒ£ã‚¹ãƒˆã€Œ{cast_name}ã€ã¸ã®ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ã‚¢ãƒ‰ãƒã‚¤ã‚¹ã‚’å‡ºã—ã¦ãã ã•ã„ã€‚

ã€ç›´è¿‘ãƒãƒ£ãƒƒãƒˆãƒ­ã‚°ã€‘
{messages_text}

{f"ã€è¿½åŠ ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã€‘{context}" if context else ""}

ä»¥ä¸‹ã®3ã‚»ã‚¯ã‚·ãƒ§ãƒ³ã§å›ç­”ã—ã¦ãã ã•ã„:

## ğŸš€ ä»Šã™ãã‚„ã‚‹ã“ã¨ï¼ˆ1-2è¡Œï¼‰
æœ€ã‚‚å„ªå…ˆåº¦ã®é«˜ã„ã‚¢ã‚¯ã‚·ãƒ§ãƒ³

## ğŸ­ é›°å›²æ°—ã®åˆ†æï¼ˆ2-3è¡Œï¼‰
ãƒãƒ£ãƒƒãƒˆå…¨ä½“ã®ãƒˆãƒ¼ãƒ³ã€ç››ã‚Šä¸ŠãŒã‚Šåº¦ã€æ³¨ç›®ã™ã¹ããƒ¦ãƒ¼ã‚¶ãƒ¼

## ğŸ“‹ æ¬¡ã®ã‚¢ã‚¯ã‚·ãƒ§ãƒ³ææ¡ˆï¼ˆ2-3é …ç›®ï¼‰
ä»Šå¾Œ5-10åˆ†ã§è©¦ã™ã¹ãã“ã¨
"""

    response = client.messages.create(
        model="claude-sonnet-4-20250514",
        max_tokens=1000,
        messages=[{"role": "user", "content": prompt}],
    )

    text = response.content[0].text
    tokens_used = response.usage.input_tokens + response.usage.output_tokens
    cost = (response.usage.input_tokens * 3 + response.usage.output_tokens * 15) / 1_000_000

    return {
        "text": text,
        "model": "claude-sonnet",
        "tokens_used": tokens_used,
        "cost_usd": round(cost, 6),
    }


async def generate_competitive_analysis(
    data: dict,
    analysis_type: str = "overview",
) -> dict:
    """ã‚­ãƒ£ã‚¹ãƒˆç«¶åˆåˆ†æãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆ"""
    client = _get_client()

    # ãƒˆãƒƒãƒ—ãƒãƒƒãƒ‘ãƒ¼æƒ…å ±
    tippers_text = "\n".join(
        f"  {i+1}. {t['name']}: {t['tokens']:,}tk"
        for i, t in enumerate(data.get("top_tippers", []))
    ) or "  ãƒ‡ãƒ¼ã‚¿ãªã—"

    # ãƒ”ãƒ¼ã‚¯æ™‚é–“å¸¯
    day_names = ["æ—¥", "æœˆ", "ç«", "æ°´", "æœ¨", "é‡‘", "åœŸ"]
    peak_text = "\n".join(
        f"  {day_names[p['day']]}æ›œ {p['hour']}æ™‚å°: {p['tokens']:.0f}tk/æ™‚"
        for p in data.get("peak_times", [])
    ) or "  ãƒ‡ãƒ¼ã‚¿ãªã—"

    prompt = f"""ä»¥ä¸‹ã®é…ä¿¡ãƒ‡ãƒ¼ã‚¿ã‹ã‚‰ã€ã“ã®ã‚­ãƒ£ã‚¹ãƒˆã®ç‰¹å¾´ã¨æˆåŠŸè¦å› ã‚’åˆ†æã—ã¦ãã ã•ã„ã€‚

ã‚­ãƒ£ã‚¹ãƒˆ: {data['cast_name']}
é…ä¿¡æ™‚é–“: {data['total_hours']:.1f}æ™‚é–“ï¼ˆ{data['total_sessions']}ã‚»ãƒƒã‚·ãƒ§ãƒ³ï¼‰
ç·ãƒãƒƒãƒ—: {data['total_tips']:,}tk
ãƒ¦ãƒ‹ãƒ¼ã‚¯ãƒãƒƒãƒ‘ãƒ¼: {data['unique_tippers']}å
å¹³å‡ãƒ”ãƒ¼ã‚¯è¦–è´è€…: {data['avg_peak_viewers']:.0f}å

ãƒˆãƒƒãƒ—ãƒãƒƒãƒ‘ãƒ¼:
{tippers_text}

ãƒãƒƒãƒ—é›†ä¸­æ™‚é–“å¸¯:
{peak_text}

ä»¥ä¸‹ã®5é …ç›®ã§åˆ†æã—ã¦ãã ã•ã„ã€‚å„é …ç›®2-3è¡Œã§ç°¡æ½”ã«:

## 1. åç›Šãƒ‘ã‚¿ãƒ¼ãƒ³
ãƒ‘ãƒ–é‡è¦– / ãƒã‚±ãƒãƒ£å›è»¢ / ãƒã‚¤ãƒ–ãƒªãƒƒãƒ‰ã®ã©ã‚Œã‹æ¨å®š

## 2. é¡§å®¢æ§‹æˆã®ç‰¹å¾´
å¤ªå®¢ä¾å­˜åº¦ã€æ–°è¦ç‡ã€å¸¸é€£æ¯”ç‡

## 3. é…ä¿¡ã‚¹ã‚¿ã‚¤ãƒ«ã®æ¨å®š
ãƒˆãƒ¼ã‚¯ãƒ³å–å¾—ãƒ‘ã‚¿ãƒ¼ãƒ³ã‹ã‚‰æ¨æ¸¬ã•ã‚Œã‚‹é…ä¿¡ã‚¹ã‚¿ã‚¤ãƒ«

## 4. å¼·ã¿ãƒ»å¼±ã¿
æ•°å€¤ã‹ã‚‰èª­ã¿å–ã‚Œã‚‹ç‰¹å¾´çš„ãªç‚¹

## 5. æ”¹å–„ææ¡ˆ
å£²ä¸Šå‘ä¸Šã®ãŸã‚ã®å…·ä½“çš„ã‚¢ãƒ‰ãƒã‚¤ã‚¹ï¼ˆ2-3é …ç›®ï¼‰
"""

    response = client.messages.create(
        model="claude-sonnet-4-20250514",
        max_tokens=2000,
        messages=[{"role": "user", "content": prompt}],
    )

    text = response.content[0].text
    tokens_used = response.usage.input_tokens + response.usage.output_tokens
    cost = (response.usage.input_tokens * 3 + response.usage.output_tokens * 15) / 1_000_000

    return {
        "text": text,
        "model": "claude-sonnet",
        "tokens_used": tokens_used,
        "cost_usd": round(cost, 6),
        "cast_name": data["cast_name"],
        "analysis_type": analysis_type,
    }


async def generate_daily_report(
    cast_name: str,
    recent_messages: list[dict],
    context: str | None = None,
) -> dict:
    """æ—¥æ¬¡ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆ"""
    client = _get_client()

    msg_lines = []
    for m in recent_messages[-100:]:
        prefix = ""
        if m.get("tokens", 0) > 0:
            prefix = f"[ğŸ{m['tokens']}tk] "
        msg_lines.append(f"{m.get('user_name', '?')}: {prefix}{m.get('message', '')}")

    messages_text = "\n".join(msg_lines)

    prompt = f"""ã‚ãªãŸã¯ãƒ©ã‚¤ãƒ–é…ä¿¡ã®ãƒãƒãƒ¼ã‚¸ãƒ£ãƒ¼ã§ã™ã€‚
ä»¥ä¸‹ã®é…ä¿¡ãƒãƒ£ãƒƒãƒˆãƒ­ã‚°ã‹ã‚‰ã€ã‚­ãƒ£ã‚¹ãƒˆã€Œ{cast_name}ã€ã®ãƒãƒãƒ¼ã‚¸ãƒ£ãƒ¼å‘ã‘ãƒ‡ã‚¤ãƒªãƒ¼ãƒ¬ãƒãƒ¼ãƒˆã‚’ä½œæˆã—ã¦ãã ã•ã„ã€‚

ã€ãƒãƒ£ãƒƒãƒˆãƒ­ã‚°ã€‘
{messages_text}

{f"ã€å£²ä¸Šãƒ»è¿½åŠ ãƒ‡ãƒ¼ã‚¿ã€‘{context}" if context else ""}

ä»¥ä¸‹ã®å½¢å¼ã§:

## ğŸ“Š é…ä¿¡ã‚µãƒãƒªãƒ¼
- é…ä¿¡ã®é›°å›²æ°—ï¼ˆ1-2è¡Œï¼‰
- ãƒãƒ£ãƒƒãƒˆæ´»ç™ºåº¦ï¼ˆé«˜/ä¸­/ä½ï¼‰

## ğŸ‹ æ³¨ç›®ãƒªã‚¹ãƒŠãƒ¼
å¤ªå®¢ãƒ»å¸¸é€£ã®å‹•å‘ã€æ–°è¦å¤ªå®¢ã®å‡ºç¾

## ğŸ’¡ æ”¹å–„ãƒã‚¤ãƒ³ãƒˆ
ãƒãƒ£ãƒƒãƒˆã®å‚¾å‘ã‹ã‚‰è¦‹ãˆã‚‹èª²é¡Œ

## ğŸ¯ æ¬¡å›é…ä¿¡ã¸ã®ææ¡ˆ
å…·ä½“çš„ãªã‚¢ã‚¯ã‚·ãƒ§ãƒ³ãƒ—ãƒ©ãƒ³
"""

    response = client.messages.create(
        model="claude-sonnet-4-20250514",
        max_tokens=1500,
        messages=[{"role": "user", "content": prompt}],
    )

    text = response.content[0].text
    tokens_used = response.usage.input_tokens + response.usage.output_tokens
    cost = (response.usage.input_tokens * 3 + response.usage.output_tokens * 15) / 1_000_000

    return {
        "text": text,
        "model": "claude-sonnet",
        "tokens_used": tokens_used,
        "cost_usd": round(cost, 6),
    }
